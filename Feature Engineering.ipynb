
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What is a parameter?**\n",
    "A parameter is a configuration variable that is internal to the model and whose value can be estimated from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. What is correlation?**\n",
    "Correlation is a statistical measure that expresses the extent to which two variables are linearly related."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. What does negative correlation mean?**\n",
    "Negative correlation means that as one variable increases, the other variable tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Define Machine Learning. What are the main components in Machine Learning?**\n",
    "Machine Learning is a field of study that gives computers the ability to learn without being explicitly programmed.\n",
    "Main components: Data, Model, Loss function, Optimizer, Evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. How does loss value help in determining whether the model is good or not?**\n",
    "A lower loss indicates that the model is predicting closer to the true values, meaning better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. What are continuous and categorical variables?**\n",
    "Continuous variables can take any value (e.g., height, weight).\n",
    "Categorical variables represent types or categories (e.g., gender, color)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. How do we handle categorical variables in Machine Learning?**\n",
    "Using encoding techniques like Label Encoding, One-Hot Encoding."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example using OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Color': ['Red', 'Blue', 'Green']})\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoded = encoder.fit_transform(df[['Color']])\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. What do you mean by training and testing a dataset?**\n",
    "Training data is used to build the model, testing data is used to evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. What is sklearn.preprocessing?**\n",
    "It's a module in scikit-learn for data preprocessing like scaling, encoding, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. What is a Test set?**\n",
    "A test set is a subset of data used to assess the performance of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 11. How do we split data for model fitting (training and testing) in Python?\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = [[1], [2], [3], [4], [5]]\n",
    "y = [1, 2, 3, 4, 5]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. How do you approach a Machine Learning problem?**\n",
    "Define problem, gather data, preprocess, split data, choose model, train model, evaluate, improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Why do we have to perform EDA before fitting a model to the data?**\n",
    "EDA helps understand patterns, detect outliers, and choose appropriate models and preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 14. How can you find correlation between variables in Python?\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "data = pd.DataFrame({\n",
    "    'A': np.random.rand(10),\n",
    "    'B': np.random.rand(10)\n",
    "})\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. What is causation? Explain difference between correlation and causation with an example.**\n",
    "Causation implies one variable causes another.\n",
    "Example: Ice cream sales and drowning are correlated, but both are caused by hot weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. What is an Optimizer?**\n",
    "An optimizer updates the model's parameters to reduce the loss.\n",
    "**Types:**\n",
    "- SGD: Updates with a fixed learning rate\n",
    "- Adam: Adaptive learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17. What is sklearn.linear_model?**\n",
    "This module contains linear models like LinearRegression, LogisticRegression, etc."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 18. What does model.fit() do? What arguments must be given?\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)  # Arguments: X (features), y (target)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 19. What does model.predict() do? What arguments must be given?\n",
    "predictions = model.predict(X_test)  # Argument: X_test (features to predict on)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20. What is feature scaling? How does it help in Machine Learning?**\n",
    "Feature scaling standardizes the range of independent variables to improve model performance and convergence."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 21. How do we perform scaling in Python?\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "scaled_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22. What is sklearn.preprocessing?**\n",
    "It's a module with methods for scaling, transforming, encoding, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**23. How do we split data for model fitting (training and testing) in Python?**\n",
    "Using `train_test_split()` from `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24. Explain data encoding?**\n",
    "Data encoding transforms categorical data into numerical format.\n",
    "Techniques: Label Encoding, One-Hot Encoding, Ordinal Encoding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
